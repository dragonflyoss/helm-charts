# Dragonfly Helm Chart Values.

# -- Override dragonfly name.
nameOverride: ""
# -- Override dragonfly fullname.
fullnameOverride: ""
# -- Install application cluster domain.
clusterDomain: "cluster.local"
# -- Override dragonfly namespace.
namespaceOverride: ""

global:
  # -- Global Docker image registry.
  imageRegistry: ""
  # -- Global Docker registry secret names as an array.
  imagePullSecrets: []
  # -- Global node labels for pod assignment.
  nodeSelector: {}
  # -- Global storageClass for Persistent Volume(s).
  storageClass: ""

manager:
  # -- Enable manager.
  enable: true
  # -- Manager name.
  name: manager
  # -- Override manager name.
  nameOverride: ""
  # -- Override manager fullname.
  fullnameOverride: ""
  # -- maxProcs Limits the number of operating system threads that can execute user-level.
  # Go code simultaneously by setting GOMAXPROCS environment variable, refer to https://golang.org/pkg/runtime.
  maxProcs: ""
  # -- Number of Pods to launch.
  replicas: 3
  image:
    # -- Image registry.
    registry: docker.io
    # -- Image repository.
    repository: dragonflyoss/manager
    # -- Image tag.
    tag: v2.3.0
    # -- Image digest.
    digest: ""
    # -- Image pull policy.
    pullPolicy: IfNotPresent
    # -- Image pull secrets.
    # @default -- `[]` (defaults to global.imagePullSecrets).
    pullSecrets: []
  # -- Host Aliases.
  hostAliases: []
  # -- hostNetwork specify if host network should be enabled.
  hostNetwork: false
  # -- Pod resource requests and limits.
  resources:
    requests:
      cpu: "0"
      memory: "0"
    limits:
      cpu: "8"
      memory: "16Gi"
  # -- Pod priorityClassName.
  priorityClassName: ""
  # -- Node labels for pod assignment.
  nodeSelector: {}
  # -- Pod terminationGracePeriodSeconds.
  terminationGracePeriodSeconds:
  # -- List of node taints to tolerate.
  tolerations: []
  # -- Pod annotations.
  podAnnotations: {}
  # -- Pod labels.
  podLabels: {}
  # -- Update strategy for replicas.
  updateStrategy:
    type: RollingUpdate
  # -- Deployment annotations.
  deploymentAnnotations: {}
  # -- Extra volumes for manager.
  extraVolumes:
    - name: logs
      emptyDir: {}
  # -- Extra volumeMounts for manager.
  extraVolumeMounts:
    - name: logs
      mountPath: /var/log/dragonfly/manager
  # -- REST service port.
  restPort: 8080
  # -- GRPC service port.
  grpcPort: 65003
  service:
    # -- Service type.
    type: ClusterIP
    # -- Service labels.
    labels: {}
    # -- Service annotations.
    annotations: {}
    # -- Service nodePort.
    nodePort: ""
  initContainer:
    # -- Pod resource requests and limits.
    resources:
      requests:
        cpu: "0"
        memory: "0"
      limits:
        cpu: "2"
        memory: "4Gi"
    image:
      # -- Image registry.
      registry: docker.io
      # -- Image repository.
      repository: busybox
      # -- Image tag.
      tag: latest
      # -- Image digest.
      digest: ""
      # -- Image pull policy.
      pullPolicy: IfNotPresent
  ingress:
    # -- Enable ingress.
    enable: false
    # -- Ingress class name. Requirement: kubernetes >=1.18.
    className: ""
    # -- Ingress annotations.
    annotations: {}
    # -- Ingress host path.
    path: /
    # -- Ingress path type. Requirement: kubernetes >=1.18.
    pathType: ImplementationSpecific
    # -- Manager ingress hosts.
    hosts: []
    # -- Ingress TLS configuration.
    tls: []
  config:
    server:
      grpc:
        # -- GRPC advertise ip.
        advertiseIP: ""
      # # GRPC server tls configuration.
      # tls:
      #   # CA certificate file path for mTLS.
      #   caCert: /etc/ssl/certs/ca.crt
      #   # Certificate file path for mTLS.
      #   cert: /etc/ssl/certs/server.crt
      #   # Key file path for mTLS.
      #   key: /etc/ssl/private/server.pem
      rest:
        tls:
          # -- Certificate file path.
          cert: ""
          # -- Key file path.
          key: ""
      # -- Work directory.
      workHome: ""
      # -- logLevel specifies the logging level for the manager.
      # Default: "info"
      # Supported values: "debug", "info", "warn", "error", "panic", "fatal"
      logLevel: "info"
      # -- Log directory.
      logDir: ""
      # -- Dynconfig cache directory.
      cacheDir: ""
      # -- Plugin directory.
      pluginDir: ""
    auth:
      jwt:
        # -- Realm name to display to the user, default value is Dragonfly.
        realm: "Dragonfly"
        # -- Key is secret key used for signing, default value is
        # encoded base64 of dragonfly.
        # Please change the key in production.
        key: "ZHJhZ29uZmx5Cg=="
        # -- Timeout is duration that a jwt token is valid,
        # default duration is two days.
        timeout: 48h
        # -- MaxRefresh field allows clients to refresh their token
        # until MaxRefresh has passed, default duration is two days.
        maxRefresh: 48h
    cache:
      redis:
        # -- Redis cache TTL duration.
        ttl: 5m
      local:
        # -- Size of LFU cache.
        size: 30000
        # -- Local cache TTL duration.
        ttl: 3m
    job:
      # -- rateLimit configuration.
      rateLimit:
        # -- fillInterval is the interval for refilling the bucket.
        fillInterval: 1m
        # -- capacity is the maximum number of requests that can be consumed in a single fillInterval.
        capacity: 10
        # -- quantum is the number of tokens taken from the bucket for each request.
        quantum: 10
      # -- gc configuration.
      gc:
        # -- interval is the interval of gc.
        interval: 3h
        # -- ttl is the ttl of job.
        ttl: 6h
      # -- Sync peers configuration.
      syncPeers:
        # -- interval is the interval for syncing all peers information from the scheduler and
        # display peers information in the manager console.
        interval: 24h
        # -- timeout is the timeout for syncing peers information from the single scheduler.
        timeout: 10m
      # -- Preheat configuration.
      preheat:
        # -- registryTimeout is the timeout for requesting registry to get token and manifest.
        registryTimeout: 1m
        tls:
          # -- insecureSkipVerify controls whether a client verifies the
          # server's certificate chain and hostname.
          insecureSkipVerify: false
        # # caCert is the CA certificate for preheat tls handshake, it can be path or PEM format string.
        # caCert: ''
    # -- Console shows log on console.
    console: true
    # -- Listen port for pprof, default is -1 (meaning disabled).
    pprofPort: -1
    # # tracing is the tracing configuration for dfdaemon.
    # tracing:
    #   # Protocol specifies the communication protocol for the tracing server.
    #   # Supported values: "http", "https", "grpc" (default: None).
    #   # This determines how tracing logs are transmitted to the server.
    #   protocol: grpc
    #   # endpoint is the endpoint to report tracing log, example: "localhost:4317".
    #   endpoint: localhost:4317
    #   # headers is the grpc's headers to send with tracing log.
    #   headers: {}
  metrics:
    # -- Enable manager metrics.
    enable: true
    service:
      # -- Service type.
      type: ClusterIP
      # -- Service labels.
      labels: {}
      # -- Service annotations.
      annotations: {}
    serviceMonitor:
      # -- Enable prometheus service monitor.
      # ref: https://github.com/coreos/prometheus-operator.
      enable: false
      # -- Additional labels.
      additionalLabels: {}
      # -- Interval at which metrics should be scraped.
      interval: 30s
      # -- Timeout after which the scrape is ended.
      scrapeTimeout: 10s
    prometheusRule:
      # -- Enable prometheus rule.
      # ref: https://github.com/coreos/prometheus-operator.
      enable: false
      # -- Additional labels.
      additionalLabels: {}
      # -- Prometheus rules.
      rules:
        - alert: ManagerDown
          expr: sum(dragonfly_manager_version{}) == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Manager instance is down
            message: Manager instance {{ "{{ $labels.instance }}" }} is down
        - alert: ManagerHighNumberOfFailedGRPCRequest
          expr: sum(rate(grpc_server_started_total{grpc_service="manager.Manager",grpc_type="unary"}[1m])) - sum(rate(grpc_server_handled_total{grpc_service="manager.Manager",grpc_type="unary",grpc_code="OK"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="manager.Manager",grpc_type="unary",grpc_code="NotFound"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="manager.Manager",grpc_type="unary",grpc_code="PermissionDenied"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="manager.Manager",grpc_type="unary",grpc_code="InvalidArgument"}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Manager has a high number of failed grpc request
            message: Manager has a high number of failed grpc request
        - alert: ManagerSuccessRateOfGRPCRequest
          expr: (sum(rate(grpc_server_handled_total{grpc_service="manager.Manager",grpc_type="unary",grpc_code="OK"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="manager.Manager",grpc_type="unary",grpc_code="NotFound"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="manager.Manager",grpc_type="unary",grpc_code="PermissionDenied"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="manager.Manager",grpc_type="unary",grpc_code="InvalidArgument"}[1m]))) / sum(rate(grpc_server_started_total{grpc_service="manager.Manager",grpc_type="unary"}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Manager's success rate of grpc request is low
            message: Manager's success rate of grpc request is low
        - alert: ManagerHighNumberOfFailedRESTRequest
          expr: sum(rate(dragonfly_manager_requests_total{}[1m])) - sum(rate(dragonfly_manager_requests_total{code=~"[12].."}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Manager has a high number of failed rest request
            message: Manager has a high number of failed rest request
        - alert: ManagerSuccessRateOfRESTRequest
          expr: sum(rate(dragonfly_manager_requests_total{code=~"[12].."}[1m])) / sum(rate(dragonfly_manager_requests_total{}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Manager's success rate of rest request is low
            message: Manager's success rate of rest request is low

scheduler:
  # -- Enable scheduler.
  enable: true
  # -- Scheduler name.
  name: scheduler
  # -- Override scheduler name.
  nameOverride: ""
  # -- Override scheduler fullname.
  fullnameOverride: ""
  # -- maxProcs Limits the number of operating system threads that can execute user-level.
  # Go code simultaneously by setting GOMAXPROCS environment variable, refer to https://golang.org/pkg/runtime.
  maxProcs: ""
  # -- Number of Pods to launch.
  replicas: 3
  image:
    # -- Image registry.
    registry: docker.io
    # -- Image repository.
    repository: dragonflyoss/scheduler
    # -- Image tag.
    tag: v2.3.0
    # -- Image digest.
    digest: ""
    # -- Image pull policy.
    pullPolicy: IfNotPresent
    # -- Image pull secrets.
    # @default -- `[]` (defaults to global.imagePullSecrets).
    pullSecrets: []
  # -- Host Aliases.
  hostAliases: []
  # -- hostNetwork specify if host network should be enabled.
  hostNetwork: false
  # -- Pod resource requests and limits.
  resources:
    requests:
      cpu: "0"
      memory: "0"
    limits:
      cpu: "8"
      memory: "16Gi"
  service:
    # -- Service type.
    type: ClusterIP
    # -- Service labels.
    labels: {}
    # -- Service annotations.
    annotations: {}
    # -- Service nodePort.
    nodePort: ""
  # -- Pod priorityClassName.
  priorityClassName: ""
  # -- Node labels for pod assignment.
  nodeSelector: {}
  # -- Pod terminationGracePeriodSeconds.
  terminationGracePeriodSeconds:
  # -- List of node taints to tolerate.
  tolerations: []
  # -- Pod annotations.
  podAnnotations: {}
  # -- Pod labels.
  podLabels: {}
  # -- Update strategy for replicas.
  updateStrategy: {}
  # -- Statefulset annotations.
  statefulsetAnnotations: {}
  # -- Pod containerPort.
  containerPort: 8002
  # -- Extra volumes for scheduler.
  extraVolumes:
    - name: logs
      emptyDir: {}
  # -- Extra volumeMounts for scheduler.
  extraVolumeMounts:
    - name: logs
      mountPath: /var/log/dragonfly/scheduler
  initContainer:
    # -- Pod resource requests and limits.
    resources:
      requests:
        cpu: "0"
        memory: "0"
      limits:
        cpu: "2"
        memory: "4Gi"
    image:
      # -- Image registry.
      registry: docker.io
      # -- Image repository.
      repository: busybox
      # -- Image tag.
      tag: latest
      # -- Image digest.
      digest: ""
      # -- Image pull policy.
      pullPolicy: IfNotPresent
  config:
    server:
      # -- Advertise ip.
      advertiseIP: ""
      # -- Advertise port.
      advertisePort: 8002
      # -- Listen ip.
      listenIP: "0.0.0.0"
      # -- Server port.
      port: 8002
    # # GRPC server tls configuration.
    # tls:
    #   # CA certificate file path for mTLS.
    #   caCert: /etc/ssl/certs/ca.crt
    #   # Certificate file path for mTLS.
    #   cert: /etc/ssl/certs/server.crt
    #   # Key file path for mTLS.
    #   key: /etc/ssl/private/server.pem
    #
      # -- Work directory.
      workHome: ""
      # -- logLevel specifies the logging level for the scheduler.
      # Default: "info"
      # Supported values: "debug", "info", "warn", "error", "panic", "fatal"
      logLevel: "info"
      # -- Log directory.
      logDir: ""
      # -- Dynconfig cache directory.
      cacheDir: ""
      # -- Plugin directory.
      pluginDir: ""
      # -- Storage directory.
      dataDir: ""
    scheduler:
      # -- Algorithm configuration to use different scheduling algorithms,
      # default configuration supports "default", "ml" and "nt".
      # "default" is the rule-based scheduling algorithm, "ml" is the machine learning scheduling algorithm.
      # It also supports user plugin extension, the algorithm value is "plugin",
      # and the compiled `d7y-scheduler-plugin-evaluator.so` file is added to
      # the dragonfly working directory plugins.
      algorithm: default
      # -- backToSourceCount is single task allows the peer to back-to-source count.
      backToSourceCount: 200
      # -- retryBackToSourceLimit reaches the limit, then the peer back-to-source.
      retryBackToSourceLimit: 3
      # -- Retry scheduling limit times.
      retryLimit: 5
      # -- Retry scheduling interval.
      retryInterval: 1s
      gc:
        # -- pieceDownloadTimeout is the timeout of downloading piece.
        pieceDownloadTimeout: 30m
        # -- peerGCInterval is the interval of peer gc.
        peerGCInterval: 5m
        # -- peerTTL is the ttl of peer. If the peer has been downloaded by other peers,
        # then PeerTTL will be reset.
        peerTTL: 720h
        # -- taskGCInterval is the interval of task gc. If all the peers have been reclaimed in the task,
        # then the task will also be reclaimed.
        taskGCInterval: 30m
        # -- hostGCInterval is the interval of host gc.
        hostGCInterval: 5m
        # -- hostTTL is time to live of host. If host announces message to scheduler,
        # then HostTTl will be reset.
        hostTTL: 1h
    dynconfig:
      # -- Type is deprecated and is no longer used.
      # Please remove it from your configuration.
      type: manager
      # -- Dynamic config refresh interval.
      refreshInterval: 1m
    host:
      # -- IDC is the idc of scheduler instance.
      idc: ""
      # -- Location is the location of scheduler instance.
      location: ""
    manager:
      # -- Associated scheduler cluster id.
      schedulerClusterID: 1
      keepAlive:
        # -- Manager keepalive interval.
        interval: 5s
    # # GRPC client tls configuration.
    # tls:
    #   # CA certificate file path for mTLS.
    #   caCert: /etc/ssl/certs/ca.crt
    #   # Certificate file path for mTLS.
    #   cert: /etc/ssl/certs/client.crt
    #   # Key file path for mTLS.
    #   key: /etc/ssl/private/client.pem
    seedPeer:
      # -- scheduler enable seed peer as P2P peer,
      # if the value is false, P2P network will not be back-to-source through
      # seed peer but by dfdaemon and preheat feature does not work.
      enable: true
    # # GRPC client tls configuration.
    # tls:
    #   # CA certificate file path for mTLS.
    #   caCert: /etc/ssl/certs/ca.crt
    #   # Certificate file path for mTLS.
    #   cert: /etc/ssl/certs/client.crt
    #   # Key file path for mTLS.
    #   key: /etc/ssl/private/client.pem
    # -- Console shows log on console.
    console: true
    # -- Listen port for pprof, default is -1 (meaning disabled).
    pprofPort: -1
    # # tracing is the tracing configuration for dfdaemon.
    # tracing:
    #   # Protocol specifies the communication protocol for the tracing server.
    #   # Supported values: "http", "https", "grpc" (default: None).
    #   # This determines how tracing logs are transmitted to the server.
    #   protocol: grpc
    #   # endpoint is the endpoint to report tracing log, example: "localhost:4317".
    #   endpoint: localhost:4317
    #   # headers is the grpc's headers to send with tracing log.
    #   headers: {}
  metrics:
    # -- Enable scheduler metrics.
    enable: true
    # -- Enable host metrics.
    enableHost: false
    service:
      # -- Service type.
      type: ClusterIP
      # -- Service labels.
      labels: {}
      # -- Service annotations.
      annotations: {}
    serviceMonitor:
      # -- Enable prometheus service monitor.
      # ref: https://github.com/coreos/prometheus-operator.
      enable: false
      # -- Additional labels.
      additionalLabels: {}
      # -- Interval at which metrics should be scraped.
      interval: 30s
      # -- Timeout after which the scrape is ended.
      scrapeTimeout: 10s
    prometheusRule:
      # -- Enable prometheus rule
      # ref: https://github.com/coreos/prometheus-operator.
      enable: false
      # -- Additional labels.
      additionalLabels: {}
      # -- Prometheus rules.
      rules:
        - alert: SchedulerDown
          expr: sum(dragonfly_scheduler_version{}) == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler instance is down
            message: Scheduler instance {{ "{{ $labels.instance }}" }} is down
        - alert: SchedulerHighNumberOfFailedDownloadPeer
          expr: sum(irate(dragonfly_scheduler_download_peer_finished_failure_total{}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Scheduler has a high number of failed download peer
            message: Scheduler has a high number of failed download peer
        - alert: SchedulerSuccessRateOfDownloadingPeer
          expr: (sum(rate(dragonfly_scheduler_download_peer_finished_total{}[1m])) - sum(rate(dragonfly_scheduler_download_peer_finished_failure_total{}[1m]))) / sum(rate(dragonfly_scheduler_download_peer_finished_total{}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler's success rate of downloading peer is low
            message: Scheduler's success rate of downloading peer is low
        - alert: SchedulerHighNumberOfFailedRegisterPeer
          expr: sum(irate(dragonfly_scheduler_register_peer_failure_total{}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Scheduler has a high number of failed register peer
            message: Scheduler has a high number of failed register peer
        - alert: SchedulerSuccessRateOfRegisterTask
          expr: (sum(rate(dragonfly_scheduler_register_peer_total{}[1m])) - sum(rate(dragonfly_scheduler_register_peer_failure_total{}[1m]))) / sum(rate(dragonfly_scheduler_register_peer_total{}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler's success rate of register peer is low
            message: Scheduler's success rate of register peer is low
        - alert: SchedulerHighNumberOfFailedLeavePeer
          expr: sum(irate(dragonfly_scheduler_leave_peer_failure_total{}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Scheduler has a high number of failed leave peer
            message: Scheduler has a high number of failed leave peer
        - alert: SchedulerSuccessRateOfLeavingPeer
          expr: (sum(rate(dragonfly_scheduler_leave_peer_total{}[1m])) - sum(rate(dragonfly_scheduler_leave_peer_failure_total{}[1m]))) / sum(rate(dragonfly_scheduler_leave_peer_total{}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler's success rate of leaving peer is low
            message: Scheduler's success rate of leaving peer is low
        - alert: SchedulerHighNumberOfFailedStatTask
          expr: sum(irate(dragonfly_scheduler_stat_task_failure_total{}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Scheduler has a high number of failed stat task
            message: Scheduler has a high number of failed stat task
        - alert: SchedulerSuccessRateOfStatTask
          expr: (sum(rate(dragonfly_scheduler_stat_task_total{}[1m])) - sum(rate(dragonfly_scheduler_stat_task_failure_total{}[1m]))) / sum(rate(dragonfly_scheduler_stat_task_total{}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler's success rate of stat task is low
            message: Scheduler's success rate of stat task is low
        - alert: SchedulerHighNumberOfFailedAnnouncePeer
          expr: sum(irate(dragonfly_scheduler_announce_peer_failure_total{}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Scheduler has a high number of failed announce peer
            message: Scheduler has a high number of failed announce peer
        - alert: SchedulerSuccessRateOfAnnouncingPeer
          expr: (sum(rate(dragonfly_scheduler_announce_peer_total{}[1m])) - sum(rate(dragonfly_scheduler_announce_peer_failure_total{}[1m]))) / sum(rate(dragonfly_scheduler_announce_peer_total{}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler's success rate of announcing peer is low
            message: Scheduler's success rate of announcing peer is low
        - alert: SchedulerHighNumberOfFailedLeaveHost
          expr: sum(irate(dragonfly_scheduler_leave_host_failure_total{}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Scheduler has a high number of failed leave host
            message: Scheduler has a high number of failed leave host
        - alert: SchedulerSuccessRateOfLeavingHost
          expr: (sum(rate(dragonfly_scheduler_leave_host_total{}[1m])) - sum(rate(dragonfly_scheduler_leave_host_failure_total{}[1m]))) / sum(rate(dragonfly_scheduler_leave_host_total{}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler's success rate of leaving host is low
            message: Scheduler's success rate of leaving host is low
        - alert: SchedulerHighNumberOfFailedAnnounceHost
          expr: sum(irate(dragonfly_scheduler_announce_host_failure_total{}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Scheduler has a high number of failed annoucne host
            message: Scheduler has a high number of failed annoucne host
        - alert: SchedulerSuccessRateOfAnnouncingHost
          expr: (sum(rate(dragonfly_scheduler_announce_host_total{}[1m])) - sum(rate(dragonfly_scheduler_announce_host_failure_total{}[1m]))) / sum(rate(dragonfly_scheduler_announce_host_total{}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler's success rate of announcing host is low
            message: Scheduler's success rate of announcing host is low
        - alert: SchedulerHighNumberOfFailedGRPCRequest
          expr: sum(rate(grpc_server_started_total{grpc_service="scheduler.Scheduler",grpc_type="unary"}[1m])) - sum(rate(grpc_server_handled_total{grpc_service="scheduler.Scheduler",grpc_type="unary",grpc_code="OK"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="scheduler.Scheduler",grpc_type="unary",grpc_code="NotFound"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="scheduler.Scheduler",grpc_type="unary",grpc_code="PermissionDenied"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="scheduler.Scheduler",grpc_type="unary",grpc_code="InvalidArgument"}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Scheduler has a high number of failed grpc request
            message: Scheduler has a high number of failed grpc request
        - alert: SchedulerSuccessRateOfGRPCRequest
          expr: (sum(rate(grpc_server_handled_total{grpc_service="scheduler.Scheduler",grpc_type="unary",grpc_code="OK"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="scheduler.Scheduler",grpc_type="unary",grpc_code="NotFound"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="scheduler.Scheduler",grpc_type="unary",grpc_code="PermissionDenied"}[1m])) + sum(rate(grpc_server_handled_total{grpc_service="scheduler.Scheduler",grpc_type="unary",grpc_code="InvalidArgument"}[1m]))) / sum(rate(grpc_server_started_total{grpc_service="scheduler.Scheduler",grpc_type="unary"}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scheduler's success rate of grpc request is low
            message: Scheduler's success rate of grpc request is low

seedClient:
  # -- Enable seed client.
  enable: true
  # -- Seed client name.
  name: seed-client
  # -- Override scheduler name.
  nameOverride: ""
  # -- Override scheduler fullname.
  fullnameOverride: ""
  # -- maxProcs Limits the number of operating system threads that can execute user-level.
  # Go code simultaneously by setting GOMAXPROCS environment variable, refer to https://golang.org/pkg/runtime.
  maxProcs: ""
  # -- Number of Pods to launch.
  replicas: 3
  image:
    # -- Image registry.
    registry: docker.io
    # -- Image repository.
    repository: dragonflyoss/client
    # -- Image tag.
    tag: v1.0.0
    # -- Image digest.
    digest: ""
    # -- Image pull policy.
    pullPolicy: IfNotPresent
    # -- Image pull secrets.
    # @default -- `[]` (defaults to global.imagePullSecrets).
    pullSecrets: []
  # -- Host Aliases.
  hostAliases: []
  # -- hostNetwork specify if host network should be enabled.
  hostNetwork: false
  # -- Pod resource requests and limits.
  resources:
    requests:
      cpu: "0"
      memory: "0"
    limits:
      cpu: "8"
      memory: "16Gi"
  # -- Pod priorityClassName.
  priorityClassName: ""
  # -- Node labels for pod assignment.
  nodeSelector: {}
  # -- Pod terminationGracePeriodSeconds.
  terminationGracePeriodSeconds:
  # -- List of node taints to tolerate.
  tolerations: []
  # -- Pod annotations.
  podAnnotations: {}
  # -- Pod labels.
  podLabels: {}
  # -- Update strategy for replicas.
  updateStrategy: {}
  # -- Statefulset annotations.
  statefulsetAnnotations: {}
  initContainer:
    # -- Pod resource requests and limits.
    resources:
      requests:
        cpu: "0"
        memory: "0"
      limits:
        cpu: "2"
        memory: "4Gi"
    image:
      # -- Image registry.
      registry: docker.io
      # -- Image repository.
      repository: busybox
      # -- Image tag.
      tag: latest
      # -- Image digest.
      digest: ""
      # -- Image pull policy.
      pullPolicy: IfNotPresent
  # -- Extra volumes for dfdaemon.
  extraVolumes:
    - name: logs
      emptyDir: {}
  # -- Extra volumeMounts for dfdaemon.
  extraVolumeMounts:
    - name: logs
      mountPath: /var/log/dragonfly/dfdaemon/
  persistence:
    # -- Enable persistence for seed peer.
    enable: true
    # -- Persistence annotations.
    annotations: {}
    # -- Persistence access modes.
    accessModes:
      - ReadWriteOnce
    # -- Persistence persistence size.
    size: 100Gi
  # # Seed client data Persistent Volume Storage Class.
  # # If defined, storageClassName: <storageClass>.
  # # If set to "-", storageClassName: "", which disables dynamic provisioning.
  # # If undefined (the default) or set to null, no storageClassName spec is
  # #   set, choosing the default provisioner.  (gp2 on AWS, standard on
  # #   GKE, AWS & OpenStack).
  # #
  # storageClass: "-".
  service:
    # -- Service type.
    type: ClusterIP
    # -- Service labels.
    labels: {}
    # -- Service annotations.
    annotations: {}
    # -- Service nodePort.
    nodePort: ""
  config:
    # -- console prints log.
    console: true
    log:
      # -- Specify the logging level [trace, debug, info, warn, error]
      level: info
    # -- host is the host configuration for dfdaemon.
    host:
      # idc is the idc of the host.
      idc: ""
      # location is the location of the host.
      location: ""
    # # hostname is the hostname of the host.
    # hostname: ""
    # # ip is the advertise ip of the host.
    # ip: ""
    server:
      # -- pluginDir is the directory to store plugins.
      pluginDir: /var/lib/dragonfly/plugins/dfdaemon/
      # -- cacheDir is the directory to store cache files.
      cacheDir: /var/cache/dragonfly/dfdaemon/
    download:
      server:
        # -- socketPath is the unix socket path for dfdaemon GRPC service.
        socketPath: /var/run/dragonfly/dfdaemon.sock
        # -- request_rate_limit is the rate limit of the download request in the download grpc server, default is 4000 req/s.
        requestRateLimit: 4000
      # -- rateLimit is the default rate limit of the download speed in GiB/Mib/Kib per second, default is 50GiB/s.
      rateLimit: 50GiB
      # --  pieceTimeout is the timeout for downloading a piece from source.
      pieceTimeout: 120s
      # -- collected_piece_timeout is the timeout for collecting one piece from the parent in the stream.
      collectedPieceTimeout: 10s
      # -- concurrentPieceCount is the number of concurrent pieces to download.
      concurrentPieceCount: 16
    upload:
      server:
        # -- port is the port to the grpc server.
        port: 4000
      # # ip is the listen ip of the grpc server.
      # ip: ""
      # # CA certificate file path for mTLS.
      # caCert: /etc/ssl/certs/ca.crt
      # # GRPC server certificate file path for mTLS.
      # cert: /etc/ssl/certs/server.crt
      # # GRPC server key file path for mTLS.
      # key: /etc/ssl/private/server.pem
        # -- request_rate_limit is the rate limit of the upload request in the upload grpc server, default is 4000 req/s.
        requestRateLimit: 4000
    # # Client configuration for remote peer's upload server.
    # client:
    #   # CA certificate file path for mTLS.
    #   caCert: /etc/ssl/certs/ca.crt
    #   # GRPC client certificate file path for mTLS.
    #   cert: /etc/ssl/certs/client.crt
    #   # GRPC client key file path for mTLS.
    #   key: /etc/ssl/private/client.pem
      #
      # -- rateLimit is the default rate limit of the upload speed in GiB/Mib/Kib per second, default is 50GiB/s.
      rateLimit: 50GiB
    manager:
      # -- addr is manager address.
      addr: ""
    # # CA certificate file path for mTLS.
    # caCert: /etc/ssl/certs/ca.crt
    # # GRPC client certificate file path for mTLS.
    # cert: /etc/ssl/certs/client.crt
    # # GRPC client key file path for mTLS.
    # key: /etc/ssl/private/client.pem
    scheduler:
      # -- announceInterval is the interval to announce peer to the scheduler.
      # Announcer will provide the scheduler with peer information for scheduling,
      # peer information includes cpu, memory, etc.
      announceInterval: 1m
      # --  scheduleTimeout is timeout for the scheduler to respond to a scheduling request from dfdaemon, default is 3 hours.
      #
      # If the scheduler's response time for a scheduling decision exceeds this timeout,
      # dfdaemon will encounter a `TokioStreamElapsed(Elapsed(()))` error.
      #
      # Behavior upon timeout:
      #   - If `enable_back_to_source` is `true`, dfdaemon will attempt to download directly
      #     from the source.
      #   - Otherwise (if `enable_back_to_source` is `false`), dfdaemon will report a download failure.
      #
      # **Important Considerations Regarding Timeout Triggers**:
      # This timeout isn't solely for the scheduler's direct response. It can also be triggered
      # if the overall duration of the client's interaction with the scheduler for a task
      # (e.g., client downloading initial pieces and reporting their status back to the scheduler)
      # exceeds `schedule_timeout`. During such client-side processing and reporting,
      # the scheduler might be awaiting these updates before sending its comprehensive
      # scheduling response, and this entire period is subject to the `schedule_timeout`.
      #
      # **Configuration Guidance**:
      # To prevent premature timeouts, `schedule_timeout` should be configured to a value
      # greater than the maximum expected time for the *entire scheduling interaction*.
      # This includes:
      #   1. The scheduler's own processing and response time.
      #   2. The time taken by the client to download any initial pieces and download all pieces finished,
      #      as this communication is part of the scheduling phase.
      #
      # Setting this value too low can lead to `TokioStreamElapsed` errors even if the
      # network and scheduler are functioning correctly but the combined interaction time
      # is longer than the configured timeout.
      scheduleTimeout: 3h
      # -- maxScheduleCount is the max count of schedule.
      maxScheduleCount: 5
    # # CA certificate file path for mTLS.
    # caCert: /etc/ssl/certs/ca.crt
    # # GRPC client certificate file path for mTLS.
    # cert: /etc/ssl/certs/client.crt
    # # GRPC client key file path for mTLS.
    # key: /etc/ssl/private/client.pem
    seedPeer:
      # -- enable indicates whether enable seed peer.
      enable: true
      # -- type is the type of seed peer.
      type: super
      # -- clusterID is the cluster id of the seed peer cluster.
      clusterID: 1
      # -- keepaliveInterval is the interval to keep alive with manager.
      keepaliveInterval: 15s
    dynconfig:
      # -- refreshInterval is the interval to refresh dynamic configuration from manager.
      refreshInterval: 1m
    storage:
      # -- dir is the directory to store task's metadata and content.
      dir: /var/lib/dragonfly/
      # -- keep indicates whether keep the task's metadata and content when the dfdaemon restarts.
      keep: true
      # -- writeBufferSize is the buffer size for writing piece to disk, default is 4MiB.
      writeBufferSize: 4194304
      # -- readBufferSize is the buffer size for reading piece from disk, default is 4MiB.
      readBufferSize: 4194304
      # -- writePieceTimeout is the timeout for writing a piece to storage(e.g., disk or cache).
      writePieceTimeout: 90s
    gc:
      # -- interval is the interval to do gc.
      interval: 900s
      policy:
        # -- taskTTL is the ttl of the task.
        taskTTL: 720h
        # # distThreshold optionally defines a specific disk capacity to be used as the base for
        # # calculating GC trigger points with `distHighThresholdPercent` and `distLowThresholdPercent`.
        # #
        # # - If a value is provided (e.g., "500GB"), the percentage-based thresholds (`distHighThresholdPercent`,
        # #   `distLowThresholdPercent`) are applied relative to this specified capacity.
        # # - If not provided or set to 0 (the default behavior), these percentage-based thresholds are applied
        # #   relative to the total actual disk space.
        # #
        # # This allows dfdaemon to effectively manage a logical portion of the disk for its cache,
        # # rather than always considering the entire disk volume.
        #
        # distThreshold: 10TiB
        # -- distHighThresholdPercent is the high threshold percent of the disk usage.
        # If the disk usage is greater than the threshold, dfdaemon will do gc.
        distHighThresholdPercent: 80
        # -- distLowThresholdPercent is the low threshold percent of the disk usage.
        # If the disk usage is less than the threshold, dfdaemon will stop gc.
        distLowThresholdPercent: 60
    proxy:
      server:
        # -- port is the port to the proxy server.
        port: 4001
      # # ip is the listen ip of the proxy server.
      # ip: ""
      # # caCert is the root CA cert path with PEM format for the proxy server to generate the server cert.
      # # If ca_cert is empty, proxy will generate a smaple CA cert by rcgen::generate_simple_self_signed.
      # # When client requests via the proxy, the client should not verify the server cert and set
      # # insecure to true. If ca_cert is not empty, proxy will sign the server cert with the CA cert. If openssl is installed,
      # # you can use openssl to generate the root CA cert and make the system trust the root CA cert.
      # # Then set the ca_cert and ca_key to the root CA cert and key path. Dfdaemon generates the server cert
      # # and key, and signs the server cert with the root CA cert. When client requests via the proxy,
      # # the proxy can intercept the request by the server cert.
      # caCert: ""
      #
      # # caKey is the root CA key path with PEM format for the proxy server to generate the server cert.
      # # If ca_key is empty, proxy will generate a smaple CA key by rcgen::generate_simple_self_signed.
      # # When client requests via the proxy, the client should not verify the server cert and set
      # # insecure to true. If ca_key is not empty, proxy will sign the server cert with the CA cert. If openssl is installed,
      # # you can use openssl to generate the root CA cert and make the system trust the root CA cert.
      # # Then set the ca_cert and ca_key to the root CA cert and key path. Dfdaemon generates the server cert
      # # and key, and signs the server cert with the root CA cert. When client requests via the proxy,
      # # the proxy can intercept the request by the server cert.
      # caKey: ""
      #
      # # basic_auth is the basic auth configuration for HTTP proxy in dfdaemon. If basic_auth is not
      # # empty, the proxy will use the basic auth to authenticate the client by Authorization
      # # header. The value of the Authorization header is "Basic base64(username:password)", refer
      # # to https://en.wikipedia.org/wiki/Basic_access_authentication.
      # basicAuth:
      #   # username is the username for basic auth.
      #   username: "admin"
      #   # password is the password for basic auth.
      #   password: "dragonfly"
      #
      # -- rules is the list of rules for the proxy server.
      # regex is the regex of the request url.
      # useTLS indicates whether use tls for the proxy backend.
      # redirect is the redirect url.
      # filteredQueryParams is the filtered query params to generate the task id.
      # When filter is ["Signature", "Expires", "ns"], for example:
      # http://example.com/xyz?Expires=e1&Signature=s1&ns=docker.io and http://example.com/xyz?Expires=e2&Signature=s2&ns=docker.io
      # will generate the same task id.
      # Default value includes the filtered query params of s3, gcs, oss, obs, cos.
      # `X-Dragonfly-Use-P2P` header can instead of the regular expression of the rule. If the value is "true",
      # the request will use P2P technology to distribute the content. If the value is "false",
      # but url matches the regular expression in rules. The request will also use P2P technology to distribute the content.
      rules:
        - regex: "blobs/sha256.*"
          # useTLS: false
          # redirect: ""
          # filteredQueryParams: []
      registryMirror:
        # -- addr is the default address of the registry mirror. Proxy will start a registry mirror service for the
        # client to pull the image. The client can use the default address of the registry mirror in
        # configuration to pull the image. The `X-Dragonfly-Registry` header can instead of the default address
        # of registry mirror.
        addr: https://index.docker.io
      # # cert is the client cert path with PEM format for the registry.
      # # If registry use self-signed cert, the client should set the
      # # cert for the registry mirror.
      # cert: ""
      #
      # -- disableBackToSource indicates whether disable to download back-to-source when download failed.
      disableBackToSource: false
      # -- prefetch pre-downloads full of the task when download with range request.
      # `X-Dragonfly-Prefetch` header's priority is higher than prefetch in config.
      # If the value is "true", the range request will prefetch the entire file.
      # If the value is "false", the range request will fetch the range content.
      prefetch: true
      # -- prefetchRateLimit is the rate limit of prefetching in GiB/Mib/Kib per second, default is 5GiB/s.
      # The prefetch request has lower priority so limit the rate to avoid occupying the bandwidth impact other download tasks.
      prefetchRateLimit: 5GiB
      # -- readBufferSize is the buffer size for reading piece from disk, default is 4MiB.
      readBufferSize: 4194304
    health:
      server:
        # -- port is the port to the health server.
        port: 4003
      # # ip is the listen ip of the health server.
      # ip: ""
    metrics:
      server:
        # -- port is the port to the metrics server.
        port: 4002
      # # ip is the listen ip of the metrics server.
      # ip: ""
    stats:
      server:
        # -- port is the port to the stats server.
        port: 4004
      # # ip is the listen ip of the stats server.
      # ip: ""
    # # tracing is the tracing configuration for dfdaemon.
    # tracing:
    #   # Protocol specifies the communication protocol for the tracing server.
    #   # Supported values: "http", "https", "grpc" (default: None).
    #   # This determines how tracing logs are transmitted to the server.
    #   protocol: grpc
    #   # endpoint is the endpoint to report tracing log, example: "localhost:4317".
    #   endpoint: localhost:4317
    #   # headers is the grpc's headers to send with tracing log.
    #   headers: {}
  metrics:
    # -- Enable seed client metrics.
    enable: true
    service:
      # -- Service type.
      type: ClusterIP
      # -- Service labels.
      labels: {}
      # -- Service annotations.
      annotations: {}
    serviceMonitor:
      # -- Enable prometheus service monitor.
      # ref: https://github.com/coreos/prometheus-operator.
      enable: false
      # -- Additional labels
      additionalLabels: {}
      # -- Interval at which metrics should be scraped.
      interval: 30s
      # -- Timeout after which the scrape is ended.
      scrapeTimeout: 10s
    prometheusRule:
      # -- Enable prometheus rule
      # ref: https://github.com/coreos/prometheus-operator.
      enable: false
      # -- Additional labels.
      additionalLabels: {}
      # -- Prometheus rules.
      rules:
        - alert: SeedClientDown
          expr: sum(dragonfly_client_version{container="seed-client"}) == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Seed client instance is down
            message: Seed client instance {{ "{{ $labels.instance }}" }} is down
        - alert: SeedClientHighNumberOfFailedDownloadTask
          expr: sum(irate(dragonfly_client_download_task_failure_total{container="seed-client"}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Seed client has a high number of failed download task
            message: Seed client has a high number of failed download task
        - alert: SeedClientSuccessRateOfDownloadingTask
          expr: (sum(rate(dragonfly_client_download_task_total{container="seed-client"}[1m])) - sum(rate(dragonfly_client_download_task_failure_total{container="seed-client"}[1m]))) / sum(rate(dragonfly_client_download_task_total{container="seed-client"}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Seed client's success rate of downloading task is low
            message: Seed client's success rate of downloading task is low

client:
  # -- Enable client.
  enable: true
  # -- Client name.
  name: client
  # -- Override scheduler name.
  nameOverride: ""
  # -- Override scheduler fullname.
  fullnameOverride: ""
  # -- maxProcs Limits the number of operating system threads that can execute user-level.
  # Go code simultaneously by setting GOMAXPROCS environment variable, refer to https://golang.org/pkg/runtime.
  maxProcs: ""
  image:
    # -- Image registry.
    registry: docker.io
    # -- Image repository.
    repository: dragonflyoss/client
    # -- Image tag.
    tag: v1.0.0
    # -- Image digest.
    digest: ""
    # -- Image pull policy.
    pullPolicy: IfNotPresent
    # -- Image pull secrets.
    # @default -- `[]` (defaults to global.imagePullSecrets).
    pullSecrets: []
  # -- Host Aliases.
  hostAliases: []
  # -- hostPID allows visibility of processes on the host for peer pod.
  hostPID: true
  # -- hostIPC specify if host IPC should be enabled for peer pod.
  hostIPC: true
  # -- hostNetwork specify if host network should be enabled for peer pod.
  hostNetwork: true
  # -- Pod resource requests and limits.
  resources:
    requests:
      cpu: "0"
      memory: "0"
    limits:
      cpu: "4"
      memory: "8Gi"
  # -- Pod priorityClassName.
  priorityClassName: ""
  # -- Node labels for pod assignment.
  nodeSelector: {}
  # -- Pod terminationGracePeriodSeconds.
  terminationGracePeriodSeconds:
  # -- List of node taints to tolerate.
  tolerations: []
  # -- Pod annotations.
  podAnnotations: {}
  # -- Pod labels.
  podLabels: {}
  # -- Update strategy for replicas.
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 20
  # -- Statefulset annotations.
  statefulsetAnnotations: {}
  initContainer:
    # -- Pod resource requests and limits.
    resources:
      requests:
        cpu: "0"
        memory: "0"
      limits:
        cpu: "2"
        memory: "4Gi"
    image:
      # -- Image registry.
      registry: docker.io
      # -- Image repository.
      repository: busybox
      # -- Image tag.
      tag: latest
      # -- Image digest.
      digest: ""
      # -- Image pull policy.
      pullPolicy: IfNotPresent
  # -- Extra volumes for dfdaemon.
  extraVolumes:
    - name: storage
      emptyDir: {}
    - name: logs
      emptyDir: {}
  # -- Extra volumeMounts for dfdaemon.
  extraVolumeMounts:
    - name: storage
      mountPath: /var/lib/dragonfly/
    - name: logs
      mountPath: /var/log/dragonfly/dfdaemon/
  dfinit:
    # -- Enable dfinit to override configuration of container runtime.
    enable: false
    # -- restartContainerRuntime indicates whether to restart container runtime when dfinit is enabled. it should be set to true when your first install dragonfly. If non-hot load configuration changes are made, the container runtime needs to be restarted.
    restartContainerRuntime: true
    image:
      # -- Image registry.
      registry: docker.io
      # -- Image repository.
      repository: dragonflyoss/dfinit
      # -- Image tag.
      tag: v1.0.0
      # -- Image digest.
      digest: ""
      # -- Image pull policy.
      pullPolicy: IfNotPresent
    config:
      # -- console prints log.
      console: true
      log:
        # -- Specify the logging level [trace, debug, info, warn, error]
        level: info
      proxy:
        # -- addr is the proxy server address of dfdaemon.
        addr: http://127.0.0.1:4001
      containerRuntime:
        containerd:
          # -- configPath is the path of containerd configuration file.
          configPath: /etc/containerd/config.toml
          # -- registries is the list of containerd registries. hostNamespace is the location where container images and artifacts are sourced,
          # refer to https://github.com/containerd/containerd/blob/main/docs/hosts.md#registry-host-namespace. The registry host namespace
          # portion is [registry_host_name|IP address][:port], such as docker.io, ghcr.io, gcr.io, etc. serverAddr specifies the default server
          # for this registry host namespace, refer to https://github.com/containerd/containerd/blob/main/docs/hosts.md#server-field.
          # capabilities is the list of capabilities in containerd configuration, refer to
          # https://github.com/containerd/containerd/blob/main/docs/hosts.md#capabilities-field.
          # skip_verify is the flag to skip verifying the server's certificate, refer to
          # https://github.com/containerd/containerd/blob/main/docs/hosts.md#bypass-tls-verification-example.
          # ca (Certificate Authority Certification) can be set to a path or an array of paths each pointing
          # to a ca file for use in authenticating with the registry namespace, refer to
          # https://github.com/containerd/containerd/blob/main/docs/hosts.md#ca-field.
          registries:
            - hostNamespace: docker.io
              serverAddr: https://index.docker.io
              capabilities: ["pull", "resolve"]
              skipVerify: true
              # ca: []
            - hostNamespace: ghcr.io
              serverAddr: https://ghcr.io
              capabilities: ["pull", "resolve"]
              skipVerify: true
              # ca: []
        # crio:
          # # -- configPath is the path of cri-o registries's configuration file.
          # configPath: /etc/containers/registries.conf
          # # -- unqualifiedSearchRegistries is an array of host[:port] registries to try when pulling an unqualified image, in order.
          # # Refer to https://github.com/containers/image/blob/main/docs/containers-registries.conf.5.md#global-settings.
          # unqualifiedSearchRegistries: ["registry.fedoraproject.org", "registry.access.redhat.com", "docker.io"]
          # # -- registries is the list of cri-o registries, refer to https://github.com/containers/image/blob/main/docs/containers-registries.conf.5.md#namespaced-registry-settings.
          # # prefix is the prefix of the user-specified image name, refer to https://github.com/containers/image/blob/main/docs/containers-registries.conf.5.md#choosing-a-registry-toml-table.
          # # location accepts the same format as the prefix field, and specifies the physical location of the prefix-rooted namespace,
          # # refer to https://github.com/containers/image/blob/main/docs/containers-registries.conf.5.md#remapping-and-mirroring-registries.
          # registries:
            # - prefix: docker.io
              # location: docker.io
            # - prefix: ghcr.io
              # location: ghcr.io
        # podman:
          # # -- configPath is the path of cri-o registries's configuration file.
          # configPath: /etc/containers/registries.conf
          # # -- unqualifiedSearchRegistries is an array of host[:port] registries to try when pulling an unqualified image, in order.
          # # Refer to https://github.com/containers/image/blob/main/docs/containers-registries.conf.5.md#global-settings.
          # unqualifiedSearchRegistries: ["registry.fedoraproject.org", "registry.access.redhat.com", "docker.io"]
          # # -- registries is the list of cri-o registries, refer to https://github.com/containers/image/blob/main/docs/containers-registries.conf.5.md#namespaced-registry-settings.
          # # prefix is the prefix of the user-specified image name, refer to https://github.com/containers/image/blob/main/docs/containers-registries.conf.5.md#choosing-a-registry-toml-table.
          # # location accepts the same format as the prefix field, and specifies the physical location of the prefix-rooted namespace,
          # # refer to https://github.com/containers/image/blob/main/docs/containers-registries.conf.5.md#remapping-and-mirroring-registries.
          # registries:
            # - prefix: docker.io
              # location: docker.io
            # - prefix: ghcr.io
              # location: ghcr.io
        # docker:
          # # -- configPath is the path of docker configuration file where the proxy addr will be set.
          # # Refer to https://docs.docker.com/engine/daemon/proxy/
          # configPath: /etc/docker/daemon.json
  config:
    # -- console prints log.
    console: true
    log:
      # -- Specify the logging level [trace, debug, info, warn, error]
      level: info
    # -- host is the host configuration for dfdaemon.
    host:
      # idc is the idc of the host.
      idc: ""
      # location is the location of the host.
      location: ""
    # # hostname is the hostname of the host.
    # hostname: ""
    # # ip is the advertise ip of the host.
    # ip: ""
    server:
      # -- pluginDir is the directory to store plugins.
      pluginDir: /var/lib/dragonfly/plugins/dfdaemon/
      # -- cacheDir is the directory to store cache files.
      cacheDir: /var/cache/dragonfly/dfdaemon/
    download:
      server:
        # -- socketPath is the unix socket path for dfdaemon GRPC service.
        socketPath: /var/run/dragonfly/dfdaemon.sock
        # -- request_rate_limit is the rate limit of the download request in the download grpc server, default is 4000 req/s.
        requestRateLimit: 4000
      # -- rateLimit is the default rate limit of the download speed in GiB/Mib/Kib per second, default is 50GiB/s.
      rateLimit: 50GiB
      # --  pieceTimeout is the timeout for downloading a piece from source.
      pieceTimeout: 120s
      # -- collected_piece_timeout is the timeout for collecting one piece from the parent in the stream.
      collectedPieceTimeout: 10s
      # -- concurrentPieceCount is the number of concurrent pieces to download.
      concurrentPieceCount: 8
    upload:
      server:
        # -- port is the port to the grpc server.
        port: 4000
      # # ip is the listen ip of the grpc server.
      # ip: ""
      # # CA certificate file path for mTLS.
      # caCert: /etc/ssl/certs/ca.crt
      # # GRPC server certificate file path for mTLS.
      # cert: /etc/ssl/certs/server.crt
      # # GRPC server key file path for mTLS.
      # key: /etc/ssl/private/server.pem
        # -- request_rate_limit is the rate limit of the upload request in the upload grpc server, default is 4000 req/s.
        requestRateLimit: 4000
    # # Client configuration for remote peer's upload server.
    # client:
    #   # CA certificate file path for mTLS.
    #   caCert: /etc/ssl/certs/ca.crt
    #   # GRPC client certificate file path for mTLS.
    #   cert: /etc/ssl/certs/client.crt
    #   # GRPC client key file path for mTLS.
    #   key: /etc/ssl/private/client.pem
      #
      # -- disableShared indicates whether disable to share data with other peers.
      disableShared: false
      # -- rateLimit is the default rate limit of the upload speed in GiB/Mib/Kib per second, default is 50GiB/s.
      rateLimit: 50GiB
    manager:
      # -- addr is manager address.
      addr: ""
    # # CA certificate file path for mTLS.
    # caCert: /etc/ssl/certs/ca.crt
    # # GRPC client certificate file path for mTLS.
    # cert: /etc/ssl/certs/client.crt
    # # GRPC client key file path for mTLS.
    # key: /etc/ssl/private/client.pem
    scheduler:
      # -- announceInterval is the interval to announce peer to the scheduler.
      # Announcer will provide the scheduler with peer information for scheduling,
      # peer information includes cpu, memory, etc.
      announceInterval: 5m
      # --  scheduleTimeout is timeout for the scheduler to respond to a scheduling request from dfdaemon, default is 3 hours.
      #
      # If the scheduler's response time for a scheduling decision exceeds this timeout,
      # dfdaemon will encounter a `TokioStreamElapsed(Elapsed(()))` error.
      #
      # Behavior upon timeout:
      #   - If `enable_back_to_source` is `true`, dfdaemon will attempt to download directly
      #     from the source.
      #   - Otherwise (if `enable_back_to_source` is `false`), dfdaemon will report a download failure.
      #
      # **Important Considerations Regarding Timeout Triggers**:
      # This timeout isn't solely for the scheduler's direct response. It can also be triggered
      # if the overall duration of the client's interaction with the scheduler for a task
      # (e.g., client downloading initial pieces and reporting their status back to the scheduler)
      # exceeds `schedule_timeout`. During such client-side processing and reporting,
      # the scheduler might be awaiting these updates before sending its comprehensive
      # scheduling response, and this entire period is subject to the `schedule_timeout`.
      #
      # **Configuration Guidance**:
      # To prevent premature timeouts, `schedule_timeout` should be configured to a value
      # greater than the maximum expected time for the *entire scheduling interaction*.
      # This includes:
      #   1. The scheduler's own processing and response time.
      #   2. The time taken by the client to download any initial pieces and download all pieces finished,
      #      as this communication is part of the scheduling phase.
      #
      # Setting this value too low can lead to `TokioStreamElapsed` errors even if the
      # network and scheduler are functioning correctly but the combined interaction time
      # is longer than the configured timeout.
      scheduleTimeout: 3h
      # -- maxScheduleCount is the max count of schedule.
      maxScheduleCount: 5
      # -- enableBackToSource indicates whether enable back-to-source download, when the scheduling failed.
      enableBackToSource: true
    # # CA certificate file path for mTLS.
    # caCert: /etc/ssl/certs/ca.crt
    # # GRPC client certificate file path for mTLS.
    # cert: /etc/ssl/certs/client.crt
    # # GRPC client key file path for mTLS.
    # key: /etc/ssl/private/client.pem
    dynconfig:
      # -- refreshInterval is the interval to refresh dynamic configuration from manager.
      refreshInterval: 5m
    storage:
      # -- dir is the directory to store task's metadata and content.
      dir: /var/lib/dragonfly/
      # -- keep indicates whether keep the task's metadata and content when the dfdaemon restarts.
      keep: true
      # -- writeBufferSize is the buffer size for writing piece to disk, default is 4MiB.
      writeBufferSize: 4194304
      # -- readBufferSize is the buffer size for reading piece from disk, default is 4MiB.
      readBufferSize: 4194304
      # -- writePieceTimeout is the timeout for writing a piece to storage(e.g., disk or cache).
      writePieceTimeout: 90s
    gc:
      # -- interval is the interval to do gc.
      interval: 900s
      policy:
        # -- taskTTL is the ttl of the task.
        taskTTL: 720h
        # # distThreshold optionally defines a specific disk capacity to be used as the base for
        # # calculating GC trigger points with `distHighThresholdPercent` and `distLowThresholdPercent`.
        # #
        # # - If a value is provided (e.g., "500GB"), the percentage-based thresholds (`distHighThresholdPercent`,
        # #   `distLowThresholdPercent`) are applied relative to this specified capacity.
        # # - If not provided or set to 0 (the default behavior), these percentage-based thresholds are applied
        # #   relative to the total actual disk space.
        # #
        # # This allows dfdaemon to effectively manage a logical portion of the disk for its cache,
        # # rather than always considering the entire disk volume.
        #
        # distThreshold: 10TiB
        # -- distHighThresholdPercent is the high threshold percent of the disk usage.
        # If the disk usage is greater than the threshold, dfdaemon will do gc.
        distHighThresholdPercent: 80
        # -- distLowThresholdPercent is the low threshold percent of the disk usage.
        # If the disk usage is less than the threshold, dfdaemon will stop gc.
        distLowThresholdPercent: 60
    proxy:
      server:
        # -- port is the port to the proxy server.
        port: 4001
      # # ip is the listen ip of the proxy server.
      # ip: ""
      # # caCert is the root CA cert path with PEM format for the proxy server to generate the server cert.
      # # If ca_cert is empty, proxy will generate a smaple CA cert by rcgen::generate_simple_self_signed.
      # # When client requests via the proxy, the client should not verify the server cert and set
      # # insecure to true. If ca_cert is not empty, proxy will sign the server cert with the CA cert. If openssl is installed,
      # # you can use openssl to generate the root CA cert and make the system trust the root CA cert.
      # # Then set the ca_cert and ca_key to the root CA cert and key path. Dfdaemon generates the server cert
      # # and key, and signs the server cert with the root CA cert. When client requests via the proxy,
      # # the proxy can intercept the request by the server cert.
      # caCert: ""
      #
      # # caKey is the root CA key path with PEM format for the proxy server to generate the server cert.
      # # If ca_key is empty, proxy will generate a smaple CA key by rcgen::generate_simple_self_signed.
      # # When client requests via the proxy, the client should not verify the server cert and set
      # # insecure to true. If ca_key is not empty, proxy will sign the server cert with the CA cert. If openssl is installed,
      # # you can use openssl to generate the root CA cert and make the system trust the root CA cert.
      # # Then set the ca_cert and ca_key to the root CA cert and key path. Dfdaemon generates the server cert
      # # and key, and signs the server cert with the root CA cert. When client requests via the proxy,
      # # the proxy can intercept the request by the server cert.
      # caKey: ""
      #
      # # basic_auth is the basic auth configuration for HTTP proxy in dfdaemon. If basic_auth is not
      # # empty, the proxy will use the basic auth to authenticate the client by Authorization
      # # header. The value of the Authorization header is "Basic base64(username:password)", refer
      # # to https://en.wikipedia.org/wiki/Basic_access_authentication.
      # basicAuth:
      #   # username is the username for basic auth.
      #   username: "admin"
      #   # password is the password for basic auth.
      #   password: "dragonfly"
      #
      # -- rules is the list of rules for the proxy server.
      # regex is the regex of the request url.
      # useTLS indicates whether use tls for the proxy backend.
      # redirect is the redirect url.
      # filteredQueryParams is the filtered query params to generate the task id.
      # When filter is ["Signature", "Expires", "ns"], for example:
      # http://example.com/xyz?Expires=e1&Signature=s1&ns=docker.io and http://example.com/xyz?Expires=e2&Signature=s2&ns=docker.io
      # will generate the same task id.
      # Default value includes the filtered query params of s3, gcs, oss, obs, cos.
      # `X-Dragonfly-Use-P2P` header can instead of the regular expression of the rule. If the value is "true",
      # the request will use P2P technology to distribute the content. If the value is "false",
      # but url matches the regular expression in rules. The request will also use P2P technology to distribute the content.
      rules:
        - regex: "blobs/sha256.*"
          # useTLS: false
          # redirect: ""
          # filteredQueryParams: []
      registryMirror:
        # -- addr is the default address of the registry mirror. Proxy will start a registry mirror service for the
        # client to pull the image. The client can use the default address of the registry mirror in
        # configuration to pull the image. The `X-Dragonfly-Registry` header can instead of the default address
        # of registry mirror.
        addr: https://index.docker.io
      # # cert is the client cert path with PEM format for the registry.
      # # If registry use self-signed cert, the client should set the
      # # cert for the registry mirror.
      # cert: ""
      #
      # -- disableBackToSource indicates whether disable to download back-to-source when download failed.
      disableBackToSource: false
      # -- prefetch pre-downloads full of the task when download with range request.
      # `X-Dragonfly-Prefetch` header's priority is higher than prefetch in config.
      # If the value is "true", the range request will prefetch the entire file.
      # If the value is "false", the range request will fetch the range content.
      prefetch: true
      # -- prefetchRateLimit is the rate limit of prefetching in GiB/Mib/Kib per second, default is 5GiB/s.
      # The prefetch request has lower priority so limit the rate to avoid occupying the bandwidth impact other download tasks.
      prefetchRateLimit: 5GiB
      # -- readBufferSize is the buffer size for reading piece from disk, default is 4MiB.
      readBufferSize: 4194304
    health:
      server:
        # -- port is the port to the health server.
        port: 4003
      # # ip is the listen ip of the health server.
      # ip: ""
    metrics:
      server:
        # -- port is the port to the metrics server.
        port: 4002
      # # ip is the listen ip of the metrics server.
      # ip: ""
    stats:
      server:
        # -- port is the port to the stats server.
        port: 4004
      # # ip is the listen ip of the stats server.
      # ip: ""
    # # tracing is the tracing configuration for dfdaemon.
    # tracing:
    #   # Protocol specifies the communication protocol for the tracing server.
    #   # Supported values: "http", "https", "grpc" (default: None).
    #   # This determines how tracing logs are transmitted to the server.
    #   protocol: grpc
    #   # endpoint is the endpoint to report tracing log, example: "localhost:4317".
    #   endpoint: localhost:4317
    #   # headers is the grpc's headers to send with tracing log.
    #   headers: {}
  metrics:
    # -- Enable client metrics.
    enable: true
    service:
      # -- Service type.
      type: ClusterIP
      # -- Service labels.
      labels: {}
      # -- Service annotations.
      annotations: {}
    serviceMonitor:
      # -- Enable prometheus service monitor.
      # ref: https://github.com/coreos/prometheus-operator.
      enable: false
      # -- Additional labels
      additionalLabels: {}
      # -- Interval at which metrics should be scraped.
      interval: 30s
      # -- Timeout after which the scrape is ended.
      scrapeTimeout: 10s
    prometheusRule:
      # -- Enable prometheus rule
      # ref: https://github.com/coreos/prometheus-operator.
      enable: false
      # -- Additional labels.
      additionalLabels: {}
      # -- Prometheus rules.
      rules:
        - alert: ClientDown
          expr: sum(dragonfly_client_version{container="client"}) == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Client instance is down
            message: Client instance {{ "{{ $labels.instance }}" }} is down
        - alert: ClientHighNumberOfFailedDownloadTask
          expr: sum(irate(dragonfly_client_download_task_failure_total{container="client"}[1m])) > 100
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Client has a high number of failed download task
            message: Client has a high number of failed download task
        - alert: ClientSuccessRateOfDownloadingTask
          expr: (sum(rate(dragonfly_client_download_task_total{container="client"}[1m])) - sum(rate(dragonfly_client_download_task_failure_total{container="client"}[1m]))) / sum(rate(dragonfly_client_download_task_total{container="client"}[1m])) < 0.6
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Client's success rate of downloading task is low
            message: Client's success rate of downloading task is low

externalManager:
  # -- External manager hostname.
  host:
  # -- External REST service port.
  restPort: 8080
  # -- External GRPC service port.
  grpcPort: 65003

mysql:
  # -- Enable mysql with docker container.
  enable: true
  # -- Cluster domain.
  clusterDomain: "cluster.local"
  # -- Running GORM migration.
  migrate: true
  auth:
    # -- Mysql hostname.
    host: ""
    # -- Mysql root password.
    rootPassword: dragonfly-root
    # -- Mysql username.
    username: dragonfly
    # -- Mysql password.
    password: dragonfly
    # -- Mysql database name.
    database: manager
  primary:
    service:
      # -- Mysql port.
      port: 3306

externalMysql:
  # -- Running GORM migration.
  migrate: true
  # -- External mysql hostname.
  host:
  # -- External mysql username.
  username: dragonfly
  # -- External mysql password.
  password: dragonfly
  # -- External mysql database name.
  database: manager
  # -- External mysql port.
  port: 3306

redis:
  # -- Enable redis cluster with docker container.
  enable: true
  # -- Cluster domain.
  clusterDomain: "cluster.local"
  auth:
    # -- Enable password authentication.
    enabled: true
    # -- Redis password.
    password: dragonfly
  master:
    service:
      ports:
        # -- Redis master service port.
        redis: 6379

externalRedis:
  # -- External redis server addresses.
  addrs:
    - "redis.example.com:6379"
  # -- External redis sentinel master name.
  masterName: ""
  # -- External redis username.
  username: ""
  # -- External redis password.
  password: ""
  # -- External redis sentinel addresses.
  sentinelUsername: ""
  # -- External redis sentinel password.
  sentinelPassword: ""
  # -- External redis db.
  db: 0
  # -- External redis broker db.
  brokerDB: 1
  # -- External redis backend db.
  backendDB: 2
